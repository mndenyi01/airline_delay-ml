{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f0d23a",
   "metadata": {},
   "source": [
    "Data Download and Understanding\n",
    "-------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 13 files\n",
      "combined dataframe shape: (7607025, 18)\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Loading Libraries and Data\n",
    "import pandas as pd\n",
    "import pathlib as Path\n",
    "\n",
    "raw_path = Path.Path('../data/raw/')\n",
    "\n",
    "files = list(raw_path.glob('*.csv'))\n",
    "print(f\"found {len(files)} files\")\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"source_file\"] = file.name  # lineage - easier to trace bugs and better auditability(Professional habit)\n",
    "    dfs.append(df)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True) # combine all dataframes into one and avoid duplicate indices\n",
    "print(f\"combined dataframe shape: {raw_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b08756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7607025 entries, 0 to 7607024\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   fl_date              object \n",
      " 1   op_unique_carrier    object \n",
      " 2   origin_airport_id    int64  \n",
      " 3   origin               object \n",
      " 4   dest_airport_id      int64  \n",
      " 5   dest                 object \n",
      " 6   dep_delay            float64\n",
      " 7   dep_delay_new        float64\n",
      " 8   arr_delay            float64\n",
      " 9   arr_delay_new        float64\n",
      " 10  cancelled            float64\n",
      " 11  diverted             float64\n",
      " 12  carrier_delay        float64\n",
      " 13  weather_delay        float64\n",
      " 14  nas_delay            float64\n",
      " 15  security_delay       float64\n",
      " 16  late_aircraft_delay  float64\n",
      " 17  source_file          object \n",
      "dtypes: float64(11), int64(2), object(5)\n",
      "memory usage: 1.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fl_date',\n",
       " 'op_unique_carrier',\n",
       " 'origin_airport_id',\n",
       " 'origin',\n",
       " 'dest_airport_id',\n",
       " 'dest',\n",
       " 'dep_delay',\n",
       " 'dep_delay_new',\n",
       " 'arr_delay',\n",
       " 'arr_delay_new',\n",
       " 'cancelled',\n",
       " 'diverted',\n",
       " 'carrier_delay',\n",
       " 'weather_delay',\n",
       " 'nas_delay',\n",
       " 'security_delay',\n",
       " 'late_aircraft_delay',\n",
       " 'source_file']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2: First Sanity check and column name conversion\n",
    "raw_df.head()\n",
    "raw_df.info()\n",
    "# raw_df.describe(include=\"all\") # for a brief statistical summary of the dataframe\n",
    "\n",
    "# Converting column names to lowercase and replacing spaces with underscores\n",
    "raw_df.columns = (\n",
    "    raw_df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "raw_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290927a",
   "metadata": {},
   "source": [
    "1. Categorical Columns\n",
    "- [FL_DATE, OP_UNIQUE_CARRIER, ORIGIN, DEST, source_file] - all objects,5.\n",
    "\n",
    "2. Numerical columns\n",
    "- 2 ints,[ORIGIN_AIRPORT_ID, DEST_AIRPORT_ID] and 11 floats[remaining columns]\n",
    "\n",
    "3. Missing values\n",
    "- Majorly in columns related Flight delay causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25428ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3:Converting data to parquet format for faster loading in future\n",
    "processed_path = Path.Path('../data/processed/')\n",
    "processed_path.mkdir(exist_ok=True)\n",
    "\n",
    "raw_df.to_parquet(\n",
    "    processed_path / \"flights_raw.parquet\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fcba3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet dataframe shape: (7607025, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>dep_delay_new</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>arr_delay_new</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/1/2025 12:00:00 AM</td>\n",
       "      <td>AA</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_ONTIME_REPORTING_APR-2025.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/1/2025 12:00:00 AM</td>\n",
       "      <td>AA</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_ONTIME_REPORTING_APR-2025.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/1/2025 12:00:00 AM</td>\n",
       "      <td>AA</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_ONTIME_REPORTING_APR-2025.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2025 12:00:00 AM</td>\n",
       "      <td>AA</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_ONTIME_REPORTING_APR-2025.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/1/2025 12:00:00 AM</td>\n",
       "      <td>AA</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>T_ONTIME_REPORTING_APR-2025.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fl_date op_unique_carrier  origin_airport_id origin  \\\n",
       "0  4/1/2025 12:00:00 AM                AA              10140    ABQ   \n",
       "1  4/1/2025 12:00:00 AM                AA              10140    ABQ   \n",
       "2  4/1/2025 12:00:00 AM                AA              10140    ABQ   \n",
       "3  4/1/2025 12:00:00 AM                AA              10140    ABQ   \n",
       "4  4/1/2025 12:00:00 AM                AA              10140    ABQ   \n",
       "\n",
       "   dest_airport_id dest  dep_delay  dep_delay_new  arr_delay  arr_delay_new  \\\n",
       "0            11298  DFW       -8.0            0.0      -11.0            0.0   \n",
       "1            11298  DFW       -2.0            0.0      -11.0            0.0   \n",
       "2            11298  DFW       -1.0            0.0      -17.0            0.0   \n",
       "3            11298  DFW       26.0           26.0       10.0           10.0   \n",
       "4            11298  DFW       50.0           50.0       32.0           32.0   \n",
       "\n",
       "   cancelled  diverted  carrier_delay  weather_delay  nas_delay  \\\n",
       "0        0.0       0.0            NaN            NaN        NaN   \n",
       "1        0.0       0.0            NaN            NaN        NaN   \n",
       "2        0.0       0.0            NaN            NaN        NaN   \n",
       "3        0.0       0.0            NaN            NaN        NaN   \n",
       "4        0.0       0.0            0.0            0.0        0.0   \n",
       "\n",
       "   security_delay  late_aircraft_delay                      source_file  \n",
       "0             NaN                  NaN  T_ONTIME_REPORTING_APR-2025.csv  \n",
       "1             NaN                  NaN  T_ONTIME_REPORTING_APR-2025.csv  \n",
       "2             NaN                  NaN  T_ONTIME_REPORTING_APR-2025.csv  \n",
       "3             NaN                  NaN  T_ONTIME_REPORTING_APR-2025.csv  \n",
       "4             0.0                 32.0  T_ONTIME_REPORTING_APR-2025.csv  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading back the parquet file to verify\n",
    "df_parquet = pd.read_parquet(processed_path / \"flights_raw.parquet\")\n",
    "print(f\"Parquet dataframe shape: {df_parquet.shape}\")\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3a937",
   "metadata": {},
   "source": [
    "Parquet file type overview\n",
    "--------------------------\n",
    "\n",
    "üîπ Excel / CSV\n",
    "- Row-based\n",
    "- Text-heavy\n",
    "- Repetitive column names\n",
    "- No type enforcement\n",
    "\n",
    "üîπ Parquet\n",
    "- Columnar storage\n",
    "- Compression per column\n",
    "- Stores schema + types\n",
    "- Only reads needed columns\n",
    "\n",
    "Example:\n",
    "- CSV: reads all 18 columns even if you need 2\n",
    "- Parquet: reads only requested columns\n",
    "\n",
    "So on my your laptop:\n",
    "- Less RAM usage\n",
    "- Faster EDA\n",
    "- Faster model training\n",
    "\n",
    "Hence this is why Parquet is industry standard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41d4c0",
   "metadata": {},
   "source": [
    "Data Review\n",
    "-----------\n",
    "\n",
    "‚úÖ We will keep both delay columns for now:-\n",
    "\n",
    "Why?\n",
    "- DEP_DELAY_NEW ‚Üí better for business regression\n",
    "- DEP_DELAY ‚Üí useful for EDA & interpretation\n",
    "\n",
    "Later:\n",
    "- Regression target ‚Üí DEP_DELAY_NEW\n",
    "- Drop the other to avoid leakage\n",
    "\n",
    "- ‚úîÔ∏èThe 5 delay causes columns provide GOLD insight but CANNOT be used as features to predict delays - IMPORTANT !!\n",
    "\n",
    "Why?\n",
    "- They are post-event explanations\n",
    "- They sum up to the delay\n",
    "- This would be target leakage\n",
    "\n",
    "üìå What they ARE good for:\n",
    "\n",
    "- Secondary regression:\n",
    "    ‚ÄúWhich cause explains most delay?‚Äù\n",
    "\n",
    "- EDA\n",
    "    Business insight dashboard\n",
    "\n",
    "It will be used in Mini regression later ‚Äî but NOT in the main predictive model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
